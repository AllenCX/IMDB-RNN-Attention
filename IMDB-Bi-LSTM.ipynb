{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from config import Config\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(\"imdb_word_index.json\") as file_json:\\n    wid_dict = json.load(file_json)\\n\\nid2w = {}\\nfor (k, v) in wid_dict.items():\\n    id2w[v] = k\\n\\nfor w in dataset[\"x_train\"][1]:\\n    print(id2w[w], end=\" \")\\n    \\nx_train, y_train, x_test, y_test, train_length, test_length, wid_dict, id2w = load_data()\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "with open(\"imdb_word_index.json\") as file_json:\n",
    "    wid_dict = json.load(file_json)\n",
    "\n",
    "id2w = {}\n",
    "for (k, v) in wid_dict.items():\n",
    "    id2w[v] = k\n",
    "\n",
    "for w in dataset[\"x_train\"][1]:\n",
    "    print(id2w[w], end=\" \")\n",
    "    \n",
    "x_train, y_train, x_test, y_test, train_length, test_length, wid_dict, id2w = load_data()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = Config(batch_size=32, \n",
    "                embedding_size=100,\n",
    "                encoder_hidden_size=200,\n",
    "                vocab_size=88584,\n",
    "                lr=0.001, \n",
    "                epoch_num=50,\n",
    "                save_per_epoch=5,\n",
    "                maxlen=100)\n",
    "\n",
    "class imdb_classifier(object):\n",
    "    def __init__(self, config, session, x_train, y_train, x_test, y_test, train_length, test_lentgh):\n",
    "        self.config = config\n",
    "        self.embedding_size = config.embedding_size\n",
    "        self.batch_size = config.batch_size\n",
    "        self.encoder_hidden_size = config.encoder_hidden_size\n",
    "        self.maxlen = config.maxlen\n",
    "        self.vocab_size = config.vocab_size\n",
    "        self.lr = config.lr\n",
    "        self.sess = session\n",
    "        self.epoch_num = config.epoch_num\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.train_length = train_length\n",
    "        self.test_length = test_length\n",
    "        \n",
    "    def build(self):\n",
    "        self.global_step = tf.Variable(0, name=\"global_step\")\n",
    "        \n",
    "        self.encoder_input = tf.placeholder(shape=(None, None), dtype=tf.int32, name=\"encoder_input\")\n",
    "        self.encoder_input_length = tf.placeholder(shape=(None,), dtype=tf.int32, name=\"encoder_input_length\")\n",
    "        self.labels = tf.placeholder(shape=(None,), dtype=tf.int32, name=\"label\")\n",
    "        self.embedding = tf.Variable(tf.random_uniform([self.vocab_size, self.embedding_size], -1.0, 1.0), \n",
    "                                     dtype=tf.float32,\n",
    "                                     name=\"embedding\")\n",
    "        self.encoder_input_embedded = tf.nn.embedding_lookup(self.embedding, \n",
    "                                                             self.encoder_input)\n",
    "        self.encoder_fw = tf.contrib.rnn.GRUCell(self.encoder_hidden_size)\n",
    "        self.encoder_bw = tf.contrib.rnn.GRUCell(self.encoder_hidden_size)\n",
    "        \n",
    "        # Since time_major == False, output shape should be [batch_size, max_time, ...]\n",
    "        ((self.encoder_fw_output, self.encoder_bw_output), \n",
    "         (self.encoder_fw_state, self.encoder_bw_state)) = (\n",
    "            tf.nn.bidirectional_dynamic_rnn(cell_fw=self.encoder_fw, \n",
    "                                            cell_bw=self.encoder_bw, \n",
    "                                            inputs=self.encoder_input_embedded,\n",
    "                                            sequence_length=self.encoder_input_length,\n",
    "                                            dtype=tf.float32)\n",
    "        )\n",
    "        \n",
    "        self.encoder_output = tf.concat((self.encoder_fw_output, self.encoder_bw_output), 2)\n",
    "        self.encoder_state = tf.concat((self.encoder_fw_state, self.encoder_bw_state), 1)\n",
    "        \n",
    "        self.output_w = tf.Variable(\n",
    "            tf.truncated_normal(shape=(self.encoder_hidden_size*2, 2), stddev=0.1), name=\"output_w\") \n",
    "        self.output_b = tf.Variable(tf.zeros(2), name=\"output_b\")\n",
    "        \n",
    "        self.logits = tf.matmul(self.encoder_output[:, -1, :], self.output_w) + self.output_b\n",
    "        self.prediction = tf.argmax(self.logits, 1)\n",
    "        \n",
    "        self.loss = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.logits, labels=self.labels)\n",
    "        )\n",
    "        \n",
    "        self.train_op = tf.train.AdamOptimizer(learning_rate=self.lr).minimize(self.loss, global_step=self.global_step)\n",
    "    def train(self, config):\n",
    "        self.build()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(self.epoch_num):\n",
    "            for x_batch, y_batch, input_length in self.minibatches(\n",
    "                self.x_train, self.y_train, self.train_length, batch_size=self.batch_size, shuffle=False):\n",
    "                # pad inputs\n",
    "                x_batch = self.padding_sequence(x_batch)\n",
    "                feed_dict = {\n",
    "                    self.encoder_input: x_batch,\n",
    "                    self.encoder_input_length: input_length,\n",
    "                    self.labels: y_batch\n",
    "                }\n",
    "                _, loss = sess.run([self.train_op, self.loss], feed_dict=feed_dict)\n",
    "                print(loss)\n",
    "    \n",
    "    def minibatches(self, inputs=None, targets=None, input_len=None, batch_size=None, shuffle=False):\n",
    "        assert len(inputs) == len(targets)\n",
    "        #assert len(inputs) == len(inputs_length)\n",
    "        if shuffle:\n",
    "            indices = np.arange(len(inputs))\n",
    "            np.random.shuffle(indices)\n",
    "        for start_idx in range(0, len(inputs) - batch_size + 1, batch_size):\n",
    "            if shuffle:\n",
    "                excerpt = indices[start_idx:start_idx + batch_size]\n",
    "            else:\n",
    "                excerpt = slice(start_idx, start_idx + batch_size)\n",
    "            yield inputs[excerpt], targets[excerpt], input_len[excerpt]\n",
    "    \n",
    "    def padding_sequence(self, inputs):\n",
    "        batch_size = len(inputs)\n",
    "        #assert self.batch_size == batch_size\n",
    "        maxlen = np.max([len(i) for i in inputs])\n",
    "        output = np.zeros([batch_size, maxlen], dtype=np.int8)\n",
    "        for i, seq in enumerate(inputs):\n",
    "            output[i, :len(seq)] = np.array(seq)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, train_length, test_length, wid_dict, id2w = load_data()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "test = imdb_classifier(config, sess, x_train, y_train, x_test, y_test, train_length, test_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.692642\n",
      "0.689341\n",
      "0.697098\n",
      "0.695244\n",
      "0.694308\n",
      "0.696904\n",
      "0.691427\n",
      "0.688735\n",
      "0.692373\n",
      "0.688031\n",
      "0.686562\n"
     ]
    }
   ],
   "source": [
    "test.train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
